{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "_K-XrAfae5e_",
        "9KYoSztSflco",
        "wS9JUMRRr8g-"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aByfaYvTxsvQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import matplotlib.transforms as mtransforms\n",
        "import matplotlib.ticker as mticker\n",
        "import matplotlib.colors as mcolors\n",
        "from matplotlib.gridspec import GridSpec\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.utils import shuffle\n",
        "import joblib\n",
        "import shap"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# CONFIGURATION\n",
        "# ========================================\n",
        "USE_EXTERNAL_VALIDATION = False  # True: run external validation | False: skip validation\n",
        "SAVE_MODEL = True  # True: save model to .pkl file | False: skip saving"
      ],
      "metadata": {
        "id": "vNifLwS7XEsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install packages for Google Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    !pip install -q matminer pymatgen\n",
        "except:\n",
        "    pass  # Packages already installed locally"
      ],
      "metadata": {
        "id": "UbynLf7yMj6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    # For Colab: upload file\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "    filename = next(iter(uploaded))\n",
        "    df = pd.read_csv(filename)\n",
        "except:\n",
        "    # For local execution: use predefined path\n",
        "    df = pd.read_csv('../data/training/Dataset_formula.csv')\n",
        "\n",
        "print(f\"Loaded {len(df)} samples with {len(df.columns)} columns\")\n",
        "display(df.head())"
      ],
      "metadata": {
        "id": "JBr6a1paMoe9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if USE_EXTERNAL_VALIDATION:\n",
        "    # Configuration: Set target property and feature type\n",
        "    property_name = \"Hc\"  # \"Hc\", \"Js\", or \"rho\"\n",
        "    featurization_method = \"WenAlloys\"  # \"Composition\", \"WenAlloys\", or \"CBFV\"\n",
        "    output_file = f\"predictions_{property_name}_{featurization_method}.xlsx\"\n",
        "    column_name = f\"{property_name}_predict\"\n",
        "\n",
        "    # Load experimental dataset\n",
        "    try:\n",
        "        # Colab: upload file\n",
        "        uploaded = files.upload()\n",
        "        X_predict = pd.read_csv('wenalloys_for_predict.csv')\n",
        "    except:\n",
        "        # Local: load from directory\n",
        "        X_predict = pd.read_csv('../data/external_validation/wenalloys_for_predict.csv')\n",
        "\n",
        "    print(f\"Loaded {len(X_predict)} experimental samples with {len(X_predict.columns)} features\")\n",
        "    display(X_predict.head())\n",
        "\n",
        "    # Initialize prediction results table (5 alloys × 2 models)\n",
        "    results = pd.DataFrame({\n",
        "        \"Model\": [\"ETR\"]*5 + [\"XGB\"]*5,\n",
        "        \"Alloy_number\": list(range(1, 6)) + list(range(1, 6)),\n",
        "        column_name: [np.nan]*10\n",
        "    })\n",
        "\n",
        "    print(f\"\\nPrediction table initialized for {property_name} ({featurization_method})\")\n",
        "    print(results, \"\\n\")"
      ],
      "metadata": {
        "id": "HyXBCkS2mf0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove rows with missing target values\n",
        "df_drop = df.dropna(subset=['Coercivity'])\n",
        "# Select formula and target columns for featurization\n",
        "df_final = df_drop.loc[:, ['formula', 'Coercivity']]"
      ],
      "metadata": {
        "id": "ZQl2hMo5NI6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "# Convert formula strings to Composition objects\n",
        "from matminer.featurizers.conversions import StrToComposition\n",
        "\n",
        "str_comp = StrToComposition(target_col_id='composition')\n",
        "df_conversion = str_comp.featurize_dataframe(df_final, col_id='formula')"
      ],
      "metadata": {
        "id": "UPIwcT4fym_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================================\n",
        "# LOAD wenalloys_corrected.py FROM GITHUB\n",
        "# ====================================================================\n",
        "import os\n",
        "import urllib.request\n",
        "\n",
        "# URL to raw file on GitHub\n",
        "WENALLOYS_URL = \"https://raw.githubusercontent.com/Niccuby/Sendust-ml-featurization-SHAP/main/scripts/wenalloys_corrected.py\"\n",
        "\n",
        "# Download if not exists\n",
        "if not os.path.exists('wenalloys_corrected.py'):\n",
        "    print(\"Downloading wenalloys_corrected.py from GitHub...\")\n",
        "    urllib.request.urlretrieve(WENALLOYS_URL, 'wenalloys_corrected.py')\n",
        "    print(\"✓ Downloaded successfully\")\n",
        "else:\n",
        "    print(\"✓ wenalloys_corrected.py already exists\")\n",
        "\n",
        "# Import module\n",
        "from wenalloys_corrected import CorrectedWenAlloys\n",
        "print(\"✓ CorrectedWenAlloys loaded successfully\")"
      ],
      "metadata": {
        "id": "q8xwV8bLOI4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "# Initialize corrected featurizer\n",
        "featurizer = CorrectedWenAlloys()\n",
        "\n",
        "# Extract WenAlloys features from composition objects\n",
        "data_featurized = featurizer.featurize_dataframe(df_conversion, col_id='composition')\n",
        "\n",
        "# Extract target variable\n",
        "y = data_featurized['Coercivity']"
      ],
      "metadata": {
        "id": "M1Xe2sbUzBV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select only WenAlloys features (exclude formula, composition, and other metadata columns)\n",
        "data_features_only = data_featurized.iloc[:, 5:]\n",
        "\n",
        "# Remove low-variance features (keep only features with 4+ unique values)\n",
        "df_drop_unique = data_features_only.loc[:, (data_features_only.nunique() >= 4)]"
      ],
      "metadata": {
        "id": "Dqj7MaARZPk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def select_wenalloys_features(df_drop_unique: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Extract manually selected WenAlloys features for Sendust alloy modeling.\n",
        "\n",
        "    Args:\n",
        "        df_drop_unique: DataFrame with all WenAlloys features after variance filtering\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with 11 manually selected physically meaningful features\n",
        "    \"\"\"\n",
        "    # List of 11 manually selected features based on domain knowledge\n",
        "    selected_features = [\n",
        "        'Yang delta',\n",
        "        'Yang omega',\n",
        "        'APE mean',\n",
        "        'Configuration entropy',\n",
        "        'Atomic weight mean',\n",
        "        'Electronegativity delta',\n",
        "        'VEC mean',\n",
        "        'Mixing enthalpy',\n",
        "        'Mean cohesive energy',\n",
        "        'Shear modulus strength model',\n",
        "        'Lambda entropy'\n",
        "    ]\n",
        "\n",
        "    # Check which features are available in the dataframe\n",
        "    available_features = [feature for feature in selected_features if feature in df_drop_unique.columns]\n",
        "\n",
        "    # Warn if any features are missing\n",
        "    if len(available_features) != len(selected_features):\n",
        "        missing_features = set(selected_features) - set(available_features)\n",
        "        print(f\"Warning: Following features not found and will be skipped: {list(missing_features)}\")\n",
        "\n",
        "    # Return dataframe with selected features only\n",
        "    return df_drop_unique[available_features].copy()\n",
        "\n",
        "\n",
        "# Apply manual feature selection (11 features for WenAlloys)\n",
        "df_the_features = select_wenalloys_features(df_drop_unique)"
      ],
      "metadata": {
        "id": "4tmLNKgniKUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename features to compact scientific notation for better readability\n",
        "df_renamed = df_the_features.rename(columns={\n",
        "    'Yang delta': 'δ',\n",
        "    'Atomic weight mean': 'A̅',\n",
        "    'Electronegativity delta': 'δχ',\n",
        "    'Mixing enthalpy': 'ΔHmix',\n",
        "    'Lambda entropy': 'Λ',\n",
        "    'Configuration entropy': 'ΔSmix',\n",
        "    'VEC mean': 'VEC',\n",
        "    'Shear modulus strength model': 'G'\n",
        "})"
      ],
      "metadata": {
        "id": "J6gpGekG6WdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare feature matrix and target vector\n",
        "features = df_renamed\n",
        "target = y\n",
        "\n",
        "# Shuffle data to ensure random distribution\n",
        "features, target = shuffle(features, target, random_state=42)\n",
        "\n",
        "# Split into training (80%) and test (20%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training samples: {len(X_train)}, Test samples: {len(X_test)}\")"
      ],
      "metadata": {
        "id": "1Iah36nid_ug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize an empty DataFrame to store all results\n",
        "model_results = pd.DataFrame(columns=['Model', 'MAE', 'MSE', 'RMSE', 'R²'])"
      ],
      "metadata": {
        "id": "YSUUfU3WK-Dd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction Properties"
      ],
      "metadata": {
        "id": "atrGb9OUbU70"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
        "import xgboost as xgb"
      ],
      "metadata": {
        "id": "kyJJLHmOw9S0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest"
      ],
      "metadata": {
        "id": "_K-XrAfae5e_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Random Forest model with pre-optimized hyperparameters\n",
        "best_model = RandomForestRegressor(\n",
        "    n_estimators=390,\n",
        "    max_depth=9,\n",
        "    min_samples_split=2,\n",
        "    min_samples_leaf=1,\n",
        "    criterion='squared_error',\n",
        "    random_state=42\n",
        ")\n",
        "best_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "6yQ4PpQbfmPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if SAVE_MODEL:\n",
        "    # Save trained model\n",
        "    joblib.dump(best_model, '1_wenalloys_coercivity_rfr.pkl')\n",
        "    print(\"✅ Model saved as '1_wenalloys_coercivity_rfr.pkl'\")\n",
        "\n",
        "    try:\n",
        "        files.download('1_wenalloys_coercivity_rfr.pkl')\n",
        "    except:\n",
        "        pass"
      ],
      "metadata": {
        "id": "L6gPqp-Bmera"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on test set\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "test_r2 = r2_score(y_test, y_pred)\n",
        "test_mae = mean_absolute_error(y_test, y_pred)\n",
        "test_mse = mean_squared_error(y_test, y_pred)\n",
        "test_rmse = np.sqrt(test_mse)\n",
        "\n",
        "# Display metrics in formatted table\n",
        "print(\"\\nTest Set Evaluation Metrics:\")\n",
        "print(\"----------------------------------------\")\n",
        "print(f\"| {'Metric':<10} | {'Value':>15} |\")\n",
        "print(\"|------------|----------------|\")\n",
        "print(f\"| R²         | {test_r2:>15.4f} |\")\n",
        "print(f\"| MAE        | {test_mae:>15.4f} |\")\n",
        "print(f\"| MSE        | {test_mse:>15.4f} |\")\n",
        "print(f\"| RMSE       | {test_rmse:>15.4f} |\")\n",
        "print(\"----------------------------------------\")"
      ],
      "metadata": {
        "id": "DjbPMNXZfq6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_and_store(model, model_name, X_test, y_test, results_df):\n",
        "    \"\"\"Evaluate model and store metrics in results DataFrame.\"\"\"\n",
        "\n",
        "    # Predict and calculate metrics\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    metrics = {\n",
        "        'Model': model_name,\n",
        "        'MAE': mean_absolute_error(y_test, y_pred),\n",
        "        'MSE': mean_squared_error(y_test, y_pred),\n",
        "        'RMSE': np.sqrt(mean_squared_error(y_test, y_pred)),\n",
        "        'R²': r2_score(y_test, y_pred)\n",
        "    }\n",
        "\n",
        "    # Add to results\n",
        "    results_df = pd.concat([results_df, pd.DataFrame([metrics])], ignore_index=True)\n",
        "    return results_df\n",
        "\n",
        "\n",
        "# Store RFR evaluation results\n",
        "model_results = evaluate_and_store(best_model, 'RFR', X_test, y_test, model_results)"
      ],
      "metadata": {
        "id": "HaIP9xkAv3gl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extra Trees Regressor"
      ],
      "metadata": {
        "id": "hVpvv6W7mf03"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Extra Trees model with pre-optimized hyperparameters\n",
        "best_model = ExtraTreesRegressor(\n",
        "    n_estimators=200,\n",
        "    max_depth=9,\n",
        "    min_samples_split=2,\n",
        "    min_samples_leaf=1,\n",
        "    criterion='absolute_error',\n",
        "    random_state=42\n",
        ")\n",
        "best_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "A2xkaSVJn4Z9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if SAVE_MODEL:\n",
        "\n",
        "# Save model to .pkl file\n",
        "    joblib.dump(best_model, '2_wenalloys_coercivity_etr.pkl')\n",
        "\n",
        "    print(\"✅ Model saved as '2_wenalloys_coercivity_etr.pkl'\")\n",
        "    try:\n",
        "        files.download('2_wenalloys_coercivity_etr.pkl')\n",
        "    except:\n",
        "        pass"
      ],
      "metadata": {
        "id": "TRwtDL9_f8hY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on test set\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "test_r2 = r2_score(y_test, y_pred)\n",
        "test_mae = mean_absolute_error(y_test, y_pred)\n",
        "test_mse = mean_squared_error(y_test, y_pred)\n",
        "test_rmse = np.sqrt(test_mse)\n",
        "\n",
        "# Display metrics in formatted table\n",
        "print(\"\\nTest Set Evaluation Metrics:\")\n",
        "print(\"----------------------------------------\")\n",
        "print(f\"| {'Metric':<10} | {'Value':>15} |\")\n",
        "print(\"|------------|----------------|\")\n",
        "print(f\"| R²         | {test_r2:>15.4f} |\")\n",
        "print(f\"| MAE        | {test_mae:>15.4f} |\")\n",
        "print(f\"| MSE        | {test_mse:>15.4f} |\")\n",
        "print(f\"| RMSE       | {test_rmse:>15.4f} |\")\n",
        "print(\"----------------------------------------\")"
      ],
      "metadata": {
        "id": "1MfF7yTBn7f2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if USE_EXTERNAL_VALIDATION:\n",
        "    # Make predictions on external validation set (ETR)\n",
        "    y_pred_etr = best_model.predict(X_predict)\n",
        "\n",
        "    # Save ETR predictions to results DataFrame\n",
        "    results.loc[results[\"Model\"] == \"ETR\", column_name] = y_pred_etr\n",
        "    print(f\"ETR predictions saved: {y_pred_etr}\")\n",
        "    print(results)\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "L6TU1zJzq8Ax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_and_store(model, model_name, X_test, y_test, results_df):\n",
        "    \"\"\"Evaluate model and store metrics in results DataFrame.\"\"\"\n",
        "\n",
        "    # Predict on test set\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate regression metrics\n",
        "    metrics = {\n",
        "        'Model': model_name,\n",
        "        'MAE': mean_absolute_error(y_test, y_pred),\n",
        "        'MSE': mean_squared_error(y_test, y_pred),\n",
        "        'RMSE': np.sqrt(mean_squared_error(y_test, y_pred)),\n",
        "        'R²': r2_score(y_test, y_pred)\n",
        "    }\n",
        "\n",
        "    # Append metrics to results DataFrame\n",
        "    results_df = pd.concat([results_df, pd.DataFrame([metrics])], ignore_index=True)\n",
        "    return results_df\n",
        "\n",
        "\n",
        "# Evaluate ETR model and store results\n",
        "model_results = evaluate_and_store(best_model, 'ETR', X_test, y_test, model_results)"
      ],
      "metadata": {
        "id": "FWfmC-t6gVO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## ====================================================================\n",
        "# SHAP BEESWARM VISUALIZATION\n",
        "# ====================================================================\n",
        "\n",
        "# Calculate SHAP values for all features using TreeExplainer\n",
        "explainer = shap.TreeExplainer(best_model, X_train)\n",
        "shap_values = explainer(X_train)\n",
        "\n",
        "# Set global font parameters\n",
        "mpl.rcParams.update({\n",
        "    'font.size': 23,\n",
        "    'axes.labelsize': 23,\n",
        "    'xtick.labelsize': 23,\n",
        "    'ytick.labelsize': 23,\n",
        "})\n",
        "\n",
        "# Create figure and axis\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "\n",
        "# Generate beeswarm plot showing feature importance and value distribution\n",
        "shap.plots.beeswarm(\n",
        "    shap_values,\n",
        "    max_display=5,                     # Show top 5 most important features\n",
        "    group_remaining_features=False,    # Don't group remaining features\n",
        "    show=False,                        # Don't display yet (for customization)\n",
        "    s=150,                             # Marker size\n",
        "    ax=ax,\n",
        "    plot_size=None\n",
        ")\n",
        "\n",
        "# Customize axis labels and ticks\n",
        "ax.set_xlabel(\"SHAP Values\", fontsize=23)\n",
        "ax.tick_params(axis='x', labelsize=23, pad=2)\n",
        "ax.tick_params(axis='y', which='both', length=0, pad=1, labelsize=23)\n",
        "\n",
        "# Set custom x-axis tick positions\n",
        "desired_ticks = [0, 15, 30, 45]\n",
        "ax.set_xticks(desired_ticks)\n",
        "\n",
        "# Shift y-axis labels to the right\n",
        "dx_pt = -3\n",
        "offset = mtransforms.ScaledTranslation(dx_pt/72.0, 0, fig.dpi_scale_trans)\n",
        "for t in ax.get_yticklabels():\n",
        "    t.set_ha('right')\n",
        "    t.set_transform(t.get_transform() + offset)\n",
        "\n",
        "# Position y-axis spine\n",
        "ax.spines['left'].set_position(('axes', 0.0))\n",
        "ax.yaxis.set_ticks_position('left')\n",
        "\n",
        "# Customize colorbar (feature value scale)\n",
        "cax = fig.axes[-1]\n",
        "cax.tick_params(pad=2, labelsize=23)\n",
        "cax.set_ylabel(\"Feature Value\", fontsize=23, labelpad=4)\n",
        "cax.yaxis.set_label_coords(2.5, 0.5)\n",
        "\n",
        "# Apply tight layout and save\n",
        "fig.tight_layout(pad=0.2)\n",
        "fig.savefig('WenAlloys_SHAP_beeswarm_Hc_ETR.png', dpi=600, bbox_inches='tight', transparent=False)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Download plot in Colab environment\n",
        "try:\n",
        "    files.download('WenAlloys_SHAP_beeswarm_Hc_ETR.png')\n",
        "except:\n",
        "    pass  # Skip download for local execution"
      ],
      "metadata": {
        "id": "Fma9FzdEuudM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def shifted_coolwarm_cmap(p, n=256):\n",
        "    \"\"\"Shift coolwarm colormap so position p becomes neutral center.\"\"\"\n",
        "    base = plt.get_cmap(\"coolwarm\")\n",
        "    xs = np.linspace(0, 1, n)\n",
        "\n",
        "    cols = []\n",
        "    for x in xs:\n",
        "        if x <= p:\n",
        "            t = 0.5 * (x / p) if p > 0 else 0.0\n",
        "        else:\n",
        "            t = 0.5 + 0.5 * ((x - p) / (1 - p)) if p < 1 else 1.0\n",
        "        cols.append(base(t))\n",
        "\n",
        "    return mcolors.ListedColormap(cols, name=\"coolwarm_shifted\")\n",
        "\n",
        "\n",
        "\n",
        "def make_coolwarm_saturated_with_center(values, vcenter=0.0, nbins=6, steps=(1, 2, 2.5, 5, 10)):\n",
        "    \"\"\"Create norm, cmap, and ticks for SHAP with saturated colors and zero at neutral.\"\"\"\n",
        "    x = np.asarray(values, dtype=float)\n",
        "    x = x[np.isfinite(x)]\n",
        "\n",
        "    # Fallback for empty data\n",
        "    if x.size == 0:\n",
        "        norm = mcolors.Normalize(vmin=-1, vmax=1, clip=True)\n",
        "        cmap = plt.get_cmap(\"coolwarm\")\n",
        "        ticks = np.array([-1, 0, 1], dtype=float)\n",
        "        return norm, cmap, ticks\n",
        "\n",
        "    data_min, data_max = float(np.min(x)), float(np.max(x))\n",
        "\n",
        "    # Normalize by actual data range for saturated colors\n",
        "    norm = mcolors.Normalize(vmin=data_min, vmax=data_max, clip=True)\n",
        "\n",
        "    # Generate ticks\n",
        "    loc = mticker.MaxNLocator(nbins=nbins, steps=list(steps))\n",
        "    ticks = loc.tick_values(data_min, data_max)\n",
        "    ticks = ticks[(ticks >= norm.vmin) & (ticks <= norm.vmax)]\n",
        "\n",
        "    # Shift colormap to place vcenter at neutral\n",
        "    if data_min < vcenter < data_max:\n",
        "        p = (vcenter - data_min) / (data_max - data_min)\n",
        "        cmap = shifted_coolwarm_cmap(p, n=256)\n",
        "\n",
        "        # Ensure vcenter is in ticks\n",
        "        if not np.any(np.isclose(ticks, vcenter)):\n",
        "            ticks = np.sort(np.append(ticks, vcenter))\n",
        "    else:\n",
        "        cmap = plt.get_cmap(\"coolwarm\")\n",
        "\n",
        "    return norm, cmap, ticks"
      ],
      "metadata": {
        "id": "nrzOXmaMVw7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================================\n",
        "# GRID-SHAP VISUALIZATION\n",
        "# ====================================================================\n",
        "\n",
        "# Calculate SHAP values using TreeExplainer\n",
        "explainer = shap.TreeExplainer(best_model, X_train)\n",
        "shap_values = explainer(X_train)\n",
        "\n",
        "# Identify top 5 most important features by mean absolute SHAP value\n",
        "mean_abs_shap_values = np.abs(shap_values.values).mean(axis=0)\n",
        "top5_indices = np.argsort(mean_abs_shap_values)[-5:][::-1]\n",
        "\n",
        "# Create figure with 3x2 grid layout\n",
        "plt.style.use('default')\n",
        "fig = plt.figure(figsize=(8, 10))\n",
        "gs = GridSpec(3, 2, figure=fig, wspace=0.65, hspace=0.5)\n",
        "\n",
        "# Generate scatter plots for each top feature\n",
        "for i, feature_index in enumerate(top5_indices):\n",
        "    feature_name = X_train.columns[feature_index]\n",
        "    row = i // 2\n",
        "    col = i % 2\n",
        "\n",
        "    ax = fig.add_subplot(gs[row, col])\n",
        "    ax.set_facecolor('#f0f0f0')\n",
        "\n",
        "    # Extract SHAP values for current feature\n",
        "    shap_col = shap_values[:, feature_index].values\n",
        "\n",
        "    # Get normalized colormap with zero at neutral center\n",
        "    norm, cmap_local, ticks = make_coolwarm_saturated_with_center(\n",
        "        shap_col,\n",
        "        vcenter=0.0,\n",
        "        nbins=6\n",
        "    )\n",
        "\n",
        "    # Create scatter plot: feature value vs target, colored by SHAP\n",
        "    sc = ax.scatter(\n",
        "        X_train[feature_name],\n",
        "        y_train,\n",
        "        c=shap_col,\n",
        "        cmap=cmap_local,\n",
        "        norm=norm,\n",
        "        alpha=0.9,\n",
        "        s=40,\n",
        "        edgecolor='black',\n",
        "        linewidth=0.25,\n",
        "        marker='o'\n",
        "    )\n",
        "\n",
        "    # Add colorbar with scientific notation\n",
        "    divider = make_axes_locatable(ax)\n",
        "    cax = divider.append_axes('right', size='5%', pad=0.05)\n",
        "    cbar = fig.colorbar(sc, cax=cax)\n",
        "\n",
        "    # Configure colorbar ticks\n",
        "    cbar.set_ticks(ticks)\n",
        "    cbar.formatter = mticker.ScalarFormatter(useMathText=False)\n",
        "    cbar.formatter.set_powerlimits((-2, 3))\n",
        "    cbar.update_ticks()\n",
        "    cbar.ax.tick_params(labelsize=11)\n",
        "    cbar.set_label('SHAP Value', fontsize=12, labelpad=5)\n",
        "\n",
        "    # Configure axes\n",
        "    ax.yaxis.set_major_locator(mticker.MaxNLocator(nbins=5, integer=True))\n",
        "    ax.set_xlabel(feature_name, fontsize=12, labelpad=4)\n",
        "    ax.set_ylabel(\"Coercivity (A/m)\", fontsize=12, labelpad=4)\n",
        "    ax.tick_params(axis='both', labelsize=11, pad=4)\n",
        "    ax.grid(True, linestyle=':', alpha=0.35, linewidth=0.45)\n",
        "\n",
        "# Save high-resolution figure\n",
        "plt.savefig('WenAlloys_Grid-SHAP_Hc_ETR.png',\n",
        "            dpi=600,\n",
        "            bbox_inches='tight',\n",
        "            facecolor='white')\n",
        "plt.show()\n",
        "\n",
        "# Download in Colab environment\n",
        "try:\n",
        "    files.download('WenAlloys_Grid-SHAP_Hc_ETR.png')\n",
        "except:\n",
        "    pass"
      ],
      "metadata": {
        "id": "LAP-lEWuV1Yw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradient Boost Regressor"
      ],
      "metadata": {
        "id": "9KYoSztSflco"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Gradient Boosting model with pre-optimized hyperparameters\n",
        "best_model = GradientBoostingRegressor(\n",
        "    n_estimators=360,\n",
        "    learning_rate=0.01159874629623866,\n",
        "    max_depth=6,\n",
        "    min_samples_split=4,\n",
        "    min_samples_leaf=1,\n",
        "    subsample=0.6205575196232219,\n",
        "    loss='huber',\n",
        "    random_state=42\n",
        ")\n",
        "best_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "BzhAd428EgK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if SAVE_MODEL:\n",
        "\n",
        "# Save model to .pkl file\n",
        "    joblib.dump(best_model, '3_wenalloys_coercivity_gbr.pkl')\n",
        "\n",
        "    print(\"✅ Model saved as '3_wenalloys_coercivity_gbr.pkl'\")\n",
        "    try:\n",
        "        files.download('3_wenalloys_coercivity_gbr.pkl')\n",
        "    except:\n",
        "        pass"
      ],
      "metadata": {
        "id": "a6_b78F7nJNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on test set\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "test_r2 = r2_score(y_test, y_pred)\n",
        "test_mae = mean_absolute_error(y_test, y_pred)\n",
        "test_mse = mean_squared_error(y_test, y_pred)\n",
        "test_rmse = np.sqrt(test_mse)\n",
        "\n",
        "# Display metrics in formatted table\n",
        "print(\"\\nTest Set Evaluation Metrics:\")\n",
        "print(\"----------------------------------------\")\n",
        "print(f\"| {'Metric':<10} | {'Value':>15} |\")\n",
        "print(\"|------------|----------------|\")\n",
        "print(f\"| R²         | {test_r2:>15.4f} |\")\n",
        "print(f\"| MAE        | {test_mae:>15.4f} |\")\n",
        "print(f\"| MSE        | {test_mse:>15.4f} |\")\n",
        "print(f\"| RMSE       | {test_rmse:>15.4f} |\")\n",
        "print(\"----------------------------------------\")"
      ],
      "metadata": {
        "id": "IeqtdUwyEWr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_and_store(model, model_name, X_test, y_test, results_df):\n",
        "    \"\"\"Evaluate model and store metrics in results DataFrame.\"\"\"\n",
        "\n",
        "    # Predict on test set\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate regression metrics\n",
        "    metrics = {\n",
        "        'Model': model_name,\n",
        "        'MAE': mean_absolute_error(y_test, y_pred),\n",
        "        'MSE': mean_squared_error(y_test, y_pred),\n",
        "        'RMSE': np.sqrt(mean_squared_error(y_test, y_pred)),\n",
        "        'R²': r2_score(y_test, y_pred)\n",
        "    }\n",
        "\n",
        "    # Append metrics to results DataFrame\n",
        "    results_df = pd.concat([results_df, pd.DataFrame([metrics])], ignore_index=True)\n",
        "    return results_df\n",
        "\n",
        "\n",
        "# Evaluate GBR model and store results\n",
        "model_results = evaluate_and_store(best_model, 'GBR', X_test, y_test, model_results)"
      ],
      "metadata": {
        "id": "sgTYWDUsxBLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGBoost Regressor"
      ],
      "metadata": {
        "id": "wS9JUMRRr8g-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate mean target for base_score initialization\n",
        "mean_target = float(y_train.mean())\n",
        "\n",
        "# Train XGBoost model with pre-optimized hyperparameters\n",
        "best_model = xgb.XGBRegressor(\n",
        "    n_estimators=492,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.01459745446326698,\n",
        "    subsample=0.673190258316676,\n",
        "    colsample_bytree=0.8416566239807235,\n",
        "    min_child_weight=1,\n",
        "    gamma=0.21276996407645865,\n",
        "    alpha=1.586330172562209,\n",
        "    random_state=42\n",
        ")\n",
        "best_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "lQl0rNV1uMBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if SAVE_MODEL:\n",
        "\n",
        "# Save model to .pkl file\n",
        "    joblib.dump(best_model, '4_wenalloys_coercivity_xgb.pkl')\n",
        "\n",
        "    print(\"✅ Model saved as '4_wenalloys_coercivity_xgb.pkl'\")\n",
        "    try:\n",
        "        files.download('4_wenalloys_coercivity_xgb.pkl')\n",
        "    except:\n",
        "        pass"
      ],
      "metadata": {
        "id": "MvuTtuTdnm2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on test set\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "test_r2 = r2_score(y_test, y_pred)\n",
        "test_mae = mean_absolute_error(y_test, y_pred)\n",
        "test_mse = mean_squared_error(y_test, y_pred)\n",
        "test_rmse = np.sqrt(test_mse)\n",
        "\n",
        "# Display metrics in formatted table\n",
        "print(\"\\nTest Set Evaluation Metrics:\")\n",
        "print(\"----------------------------------------\")\n",
        "print(f\"| {'Metric':<10} | {'Value':>15} |\")\n",
        "print(\"|------------|----------------|\")\n",
        "print(f\"| R²         | {test_r2:>15.4f} |\")\n",
        "print(f\"| MAE        | {test_mae:>15.4f} |\")\n",
        "print(f\"| MSE        | {test_mse:>15.4f} |\")\n",
        "print(f\"| RMSE       | {test_rmse:>15.4f} |\")\n",
        "print(\"----------------------------------------\")"
      ],
      "metadata": {
        "id": "PsQH4ijDuQAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if USE_EXTERNAL_VALIDATION:\n",
        "    # Make predictions on external validation set (XGB)\n",
        "    y_pred_xgb = best_model.predict(X_predict)\n",
        "\n",
        "    # Save XGB predictions to results DataFrame\n",
        "    results.loc[results[\"Model\"] == \"XGB\", column_name] = y_pred_xgb\n",
        "    print(f\"XGB predictions saved: {y_pred_xgb}\")\n",
        "    print(results)\n",
        "    print(\"\\n\")\n",
        "\n",
        "    # Add experimental ground truth values\n",
        "    y_true = [5.6, 5.47, 26.16, 47.29, 26.24]  # ← UPDATE WITH ACTUAL VALUES\n",
        "    results[\"y_true\"] = y_true * 2  # Duplicate for both models\n",
        "\n",
        "    # Calculate errors\n",
        "    results[\"error\"] = results[column_name] - results[\"y_true\"]\n",
        "    results[\"abs_error\"] = results[\"error\"].abs()\n",
        "    results[\"abs_percent_error_%\"] = 100 * results[\"abs_error\"] / results[\"y_true\"]\n",
        "\n",
        "    # Calculate average metrics per model\n",
        "    for model in [\"ETR\", \"XGB\"]:\n",
        "        mask = results[\"Model\"] == model\n",
        "        mae = results.loc[mask, \"abs_error\"].mean()\n",
        "        mape = results.loc[mask, \"abs_percent_error_%\"].mean()\n",
        "        print(f\"{model}: MAE = {mae:.4f}, MAPE = {mape:.2f}%\")\n",
        "\n",
        "    # Save results to Excel\n",
        "    results.to_excel(output_file, index=False, engine='openpyxl')\n",
        "    print(f\"✓ Results saved to {output_file}\")\n",
        "\n",
        "    # Download file (Colab only)\n",
        "    try:\n",
        "        files.download(output_file)\n",
        "    except:\n",
        "        pass"
      ],
      "metadata": {
        "id": "1vAN2AcWn3tS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_and_store(model, model_name, X_test, y_test, results_df):\n",
        "    \"\"\"\n",
        "    Evaluate model and store results in the results DataFrame\n",
        "    Returns updated DataFrame\n",
        "    \"\"\"\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    metrics = {\n",
        "        'Model': model_name,\n",
        "        'MAE': mean_absolute_error(y_test, y_pred),\n",
        "        'MSE': mean_squared_error(y_test, y_pred),\n",
        "        'RMSE': np.sqrt(mean_squared_error(y_test, y_pred)),\n",
        "        'R²': r2_score(y_test, y_pred)\n",
        "    }\n",
        "\n",
        "\n",
        "    results_df = pd.concat([results_df, pd.DataFrame([metrics])], ignore_index=True)\n",
        "    return results_df\n",
        "\n",
        "\n",
        "model_results = evaluate_and_store(best_model, 'XGB', X_test, y_test, model_results)"
      ],
      "metadata": {
        "id": "8ljK-AipRh37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_train_test_relationship(model, X_train, y_train, X_test, y_test, model_name=\"Model\"):\n",
        "    # Set up figure\n",
        "    plt.figure(figsize=(8, 6), dpi=300)\n",
        "\n",
        "    # Get predictions\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_test_pred = model.predict(X_test)\n",
        "\n",
        "    # Create scatter plots with\n",
        "    plt.scatter(y_train, y_train_pred, alpha=0.8, label='Training', color='#2408b1', s=150)\n",
        "    plt.scatter(y_test, y_test_pred, alpha=0.8, label='Test', color='#ca4016', s=150)\n",
        "\n",
        "    # Plot perfect prediction line\n",
        "    max_val = max(np.max(y_train), np.max(y_test), np.max(y_train_pred), np.max(y_test_pred))\n",
        "    min_val = min(np.min(y_train), np.min(y_test), np.min(y_train_pred), np.min(y_test_pred))\n",
        "    plt.plot([min_val, max_val], [min_val, max_val], '--', color='black',\n",
        "             label='Perfect Prediction', linewidth=4)\n",
        "\n",
        "    # Calculate and display R² scores\n",
        "    train_r2 = r2_score(y_train, y_train_pred)\n",
        "    test_r2 = r2_score(y_test, y_test_pred)\n",
        "    plt.text(0.05, 0.9, f'Train $R^2$ = {train_r2:.2f}', transform=plt.gca().transAxes,\n",
        "             color='#2408b1', fontsize=22)\n",
        "    plt.text(0.05, 0.82, f'Test $R^2$ = {test_r2:.2f}', transform=plt.gca().transAxes,\n",
        "             color='#ca4016', fontsize=22)\n",
        "\n",
        "    # Format plot\n",
        "    plt.xlabel('Actual Coercivity (A/m)', fontsize=22)\n",
        "    plt.ylabel('Predicted Coercivity (A/m)', fontsize=22)\n",
        "\n",
        "    # Adjust legend\n",
        "    plt.legend(fontsize=20, framealpha=1)\n",
        "\n",
        "    # Customize grid\n",
        "    plt.grid(True, linestyle='--', alpha=0.5)\n",
        "\n",
        "    # Adjust ticks\n",
        "    plt.tick_params(axis='both', which='major', labelsize=20)\n",
        "\n",
        "    # Set axis limits to crop at 110\n",
        "    plt.xlim(0, 110)\n",
        "    plt.ylim(0, 110)\n",
        "\n",
        "    # Tight layout\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "u7sgczADH6Uz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_train_test_relationship(best_model, X_train, y_train, X_test, y_test, model_name=\"XGBoost\")"
      ],
      "metadata": {
        "id": "Q572AQVWnfwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================================\n",
        "# SHAP BEESWARM VISUALIZATION (XGBOOST)\n",
        "# ====================================================================\n",
        "\n",
        "# Create DMatrix for XGBoost native SHAP calculation\n",
        "dmatrix_train = xgb.DMatrix(X_train, feature_names=X_train.columns.tolist())\n",
        "\n",
        "# Calculate SHAP values using XGBoost native API\n",
        "shap_values_raw = best_model.get_booster().predict(dmatrix_train, pred_contribs=True)\n",
        "shap_values_matrix = shap_values_raw[:, :-1]  # Feature contributions\n",
        "expected_value = float(shap_values_raw[0, -1])  # Base value\n",
        "\n",
        "print(f\"Shape SHAP values: {shap_values_matrix.shape}\")\n",
        "print(f\"Expected value: {expected_value}\")\n",
        "\n",
        "# Create SHAP Explanation object\n",
        "explanation = shap.Explanation(\n",
        "    values=shap_values_matrix,\n",
        "    base_values=np.full(len(X_train), expected_value),\n",
        "    data=X_train.values,\n",
        "    feature_names=X_train.columns.tolist()\n",
        ")\n",
        "\n",
        "# Set global font parameters for publication-quality plots\n",
        "mpl.rcParams.update({\n",
        "    'font.size': 23,\n",
        "    'axes.labelsize': 23,\n",
        "    'xtick.labelsize': 23,\n",
        "    'ytick.labelsize': 23,\n",
        "})\n",
        "\n",
        "# Create figure and axis\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "\n",
        "# Generate beeswarm plot showing feature importance and value distribution\n",
        "shap.plots.beeswarm(\n",
        "    explanation,\n",
        "    max_display=5,                     # Show top 5 most important features\n",
        "    group_remaining_features=False,    # Don't group remaining features\n",
        "    show=False,                        # Don't display yet (for customization)\n",
        "    s=150,                             # Marker size\n",
        "    ax=ax,\n",
        "    plot_size=None\n",
        ")\n",
        "\n",
        "# Customize axis labels and ticks\n",
        "ax.set_xlabel(\"SHAP Values\", fontsize=23)\n",
        "ax.tick_params(axis='x', labelsize=23, pad=2)\n",
        "ax.tick_params(axis='y', which='both', length=0, pad=1, labelsize=23)\n",
        "\n",
        "# Set custom x-axis tick positions\n",
        "desired_ticks = [0, 40, 80, 120]\n",
        "ax.set_xticks(desired_ticks)\n",
        "\n",
        "# Shift y-axis labels to the right for better readability\n",
        "dx_pt = -3\n",
        "offset = mtransforms.ScaledTranslation(dx_pt/72.0, 0, fig.dpi_scale_trans)\n",
        "for t in ax.get_yticklabels():\n",
        "    t.set_ha('right')\n",
        "    t.set_transform(t.get_transform() + offset)\n",
        "\n",
        "# Position y-axis spine\n",
        "ax.spines['left'].set_position(('axes', 0.0))\n",
        "ax.yaxis.set_ticks_position('left')\n",
        "\n",
        "# Customize colorbar (feature value scale)\n",
        "cax = fig.axes[-1]\n",
        "cax.tick_params(pad=2, labelsize=23)\n",
        "cax.set_ylabel(\"Feature Value\", fontsize=23, labelpad=4)\n",
        "cax.yaxis.set_label_coords(2.5, 0.5)\n",
        "\n",
        "# Apply tight layout and save\n",
        "fig.tight_layout(pad=0.2)\n",
        "fig.savefig('WenAlloys_SHAP_beeswarm_Hc_XGB.png', dpi=600, bbox_inches='tight', transparent=False)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Download plot in Colab environment\n",
        "try:\n",
        "    files.download('WenAlloys_SHAP_beeswarm_Hc_XGB.png')\n",
        "except:\n",
        "    pass  # Skip download for local execution"
      ],
      "metadata": {
        "id": "oPgEWiKmo7XN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # ====================================================================\n",
        "# SHAP BEESWARM VISUALIZATION - ZOOMED (XGBOOST)\n",
        "# ====================================================================\n",
        "\n",
        "# Create SHAP Explanation object\n",
        "explanation = shap.Explanation(\n",
        "    values=shap_values_matrix,\n",
        "    base_values=np.full(len(X_train), expected_value),\n",
        "    data=X_train.values,\n",
        "    feature_names=X_train.columns.tolist()\n",
        ")\n",
        "\n",
        "# Set global font parameters for publication-quality plots\n",
        "mpl.rcParams.update({\n",
        "    'font.size': 23,\n",
        "    'axes.labelsize': 23,\n",
        "    'xtick.labelsize': 23,\n",
        "    'ytick.labelsize': 23,\n",
        "})\n",
        "\n",
        "# Create figure and axis\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "\n",
        "# Generate beeswarm plot\n",
        "shap.plots.beeswarm(\n",
        "    explanation,\n",
        "    max_display=5,\n",
        "    group_remaining_features=False,\n",
        "    show=False,\n",
        "    s=150,\n",
        "    ax=ax,\n",
        "    plot_size=None\n",
        ")\n",
        "\n",
        "# Customize axis labels and ticks\n",
        "ax.set_xlabel(\"SHAP Values\", fontsize=23)\n",
        "ax.tick_params(axis='x', labelsize=23, pad=2)\n",
        "ax.tick_params(axis='y', which='both', length=0, pad=1, labelsize=23)\n",
        "\n",
        "# Set custom x-axis tick positions for zoomed view\n",
        "desired_ticks = [0, 10, 30]\n",
        "ax.set_xticks(desired_ticks)\n",
        "\n",
        "# Zoom into specific SHAP value range for better detail\n",
        "ax.set_xlim(-8, 20)\n",
        "\n",
        "# Shift y-axis labels to the right for better readability\n",
        "dx_pt = -3\n",
        "offset = mtransforms.ScaledTranslation(dx_pt/72.0, 0, fig.dpi_scale_trans)\n",
        "for t in ax.get_yticklabels():\n",
        "    t.set_ha('right')\n",
        "    t.set_transform(t.get_transform() + offset)\n",
        "\n",
        "# Position y-axis spine\n",
        "ax.spines['left'].set_position(('axes', 0.0))\n",
        "ax.yaxis.set_ticks_position('left')\n",
        "\n",
        "# Customize colorbar\n",
        "cax = fig.axes[-1]\n",
        "cax.tick_params(pad=2, labelsize=23)\n",
        "cax.set_ylabel(\"Coercivity\", fontsize=23, labelpad=4)\n",
        "cax.yaxis.set_label_coords(2.5, 0.5)\n",
        "\n",
        "# Apply tight layout and save\n",
        "fig.tight_layout(pad=0.2)\n",
        "fig.savefig('WenAlloys_SHAP_beeswarm_Hc_XGB_zoomed.png', dpi=600, bbox_inches='tight', transparent=False)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Download plot in Colab environment\n",
        "try:\n",
        "    files.download('WenAlloys_SHAP_beeswarm_Hc_XGB_zoomed.png')\n",
        "except:\n",
        "    pass  # Skip download for local execution"
      ],
      "metadata": {
        "id": "kYkuTF3_d6Yo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============ FUNCTION 1: Shifted coolwarm ============\n",
        "def shifted_coolwarm_cmap(p, n=256):\n",
        "    \"\"\"\n",
        "    Shift coolwarm colormap so position p becomes neutral center.\n",
        "\n",
        "    \"\"\"\n",
        "    base = plt.get_cmap(\"coolwarm\")\n",
        "    xs = np.linspace(0, 1, n)\n",
        "\n",
        "    cols = []\n",
        "    for x in xs:\n",
        "        if x <= p:\n",
        "            t = 0.5 * (x / p) if p > 0 else 0.0\n",
        "        else:\n",
        "            t = 0.5 + 0.5 * ((x - p) / (1 - p)) if p < 1 else 1.0\n",
        "        cols.append(base(t))\n",
        "\n",
        "    return mcolors.ListedColormap(cols, name=\"coolwarm_shifted\")\n",
        "\n",
        "\n",
        "# ============ FUNCTION 2: Normalization + ticks + colormap ============\n",
        "def make_coolwarm_saturated_with_center(values, vcenter=0.0, nbins=6, steps=(1, 2, 2.5, 5, 10)):\n",
        "    \"\"\"\n",
        "    Create norm, cmap, and ticks for SHAP visualization with saturated colors and zero at neutral.\n",
        "\n",
        "    \"\"\"\n",
        "    x = np.asarray(values, dtype=float)\n",
        "    x = x[np.isfinite(x)]\n",
        "\n",
        "    # Fallback for empty data\n",
        "    if x.size == 0:\n",
        "        norm = mcolors.Normalize(vmin=-1, vmax=1, clip=True)\n",
        "        cmap = plt.get_cmap(\"coolwarm\")\n",
        "        ticks = np.array([-1, 0, 1], dtype=float)\n",
        "        return norm, cmap, ticks\n",
        "\n",
        "    data_min, data_max = float(np.min(x)), float(np.max(x))\n",
        "\n",
        "    # Normalize by actual data range for saturated colors\n",
        "    norm = mcolors.Normalize(vmin=data_min, vmax=data_max, clip=True)\n",
        "\n",
        "    # Generate scientific ticks\n",
        "    loc = mticker.MaxNLocator(nbins=nbins, steps=list(steps))\n",
        "    ticks = loc.tick_values(data_min, data_max)\n",
        "\n",
        "    # Clip ticks to norm range\n",
        "    ticks = ticks[(ticks >= norm.vmin) & (ticks <= norm.vmax)]\n",
        "\n",
        "    # Shift colormap to place vcenter at neutral\n",
        "    if data_min < vcenter < data_max:\n",
        "        p = (vcenter - data_min) / (data_max - data_min)\n",
        "        cmap = shifted_coolwarm_cmap(p, n=256)\n",
        "\n",
        "        # Ensure vcenter is in ticks\n",
        "        if not np.any(np.isclose(ticks, vcenter)):\n",
        "            ticks = np.sort(np.append(ticks, vcenter))\n",
        "    else:\n",
        "        # Use standard coolwarm if vcenter is outside range\n",
        "        cmap = plt.get_cmap(\"coolwarm\")\n",
        "\n",
        "    return norm, cmap, ticks"
      ],
      "metadata": {
        "id": "tcaJnpeUYVow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================================\n",
        "# GRID-SHAP VISUALIZATION FOR XGBOOST\n",
        "# ====================================================================\n",
        "\n",
        "# Create DMatrix for XGBoost native SHAP calculation\n",
        "dmatrix_train = xgb.DMatrix(X_train, feature_names=X_train.columns.tolist())\n",
        "\n",
        "# Calculate SHAP values using XGBoost native API\n",
        "shap_values_raw = best_model.get_booster().predict(dmatrix_train, pred_contribs=True)\n",
        "shap_values_matrix = shap_values_raw[:, :-1]  # Feature contributions\n",
        "expected_value = float(shap_values_raw[0, -1])  # Base value\n",
        "\n",
        "# Create SHAP Explanation object\n",
        "explanation = shap.Explanation(\n",
        "    values=shap_values_matrix,\n",
        "    base_values=np.full(len(X_train), expected_value),\n",
        "    data=X_train.values,\n",
        "    feature_names=X_train.columns.tolist()\n",
        ")\n",
        "\n",
        "print(f\"Shape SHAP values: {shap_values_matrix.shape}\")\n",
        "print(f\"Expected value: {expected_value}\")\n",
        "\n",
        "# Identify top 5 most important features by mean absolute SHAP value\n",
        "mean_abs_shap_values = np.abs(explanation.values).mean(axis=0)\n",
        "top5_indices = np.argsort(mean_abs_shap_values)[-5:][::-1]\n",
        "\n",
        "# Create figure with 3x2 grid layout\n",
        "plt.style.use('default')\n",
        "fig = plt.figure(figsize=(8, 10))\n",
        "gs = GridSpec(3, 2, figure=fig, wspace=0.65, hspace=0.5)\n",
        "\n",
        "# Generate scatter plots for each top feature\n",
        "for i, feature_index in enumerate(top5_indices):\n",
        "    feature_name = X_train.columns[feature_index]\n",
        "    row = i // 2\n",
        "    col = i % 2\n",
        "\n",
        "    ax = fig.add_subplot(gs[row, col])\n",
        "    ax.set_facecolor('#f0f0f0')\n",
        "\n",
        "    # Extract SHAP values for current feature\n",
        "    shap_col = explanation[:, feature_index].values\n",
        "\n",
        "    # Get normalized colormap with zero at neutral center\n",
        "    norm, cmap_local, ticks = make_coolwarm_saturated_with_center(\n",
        "        shap_col,\n",
        "        vcenter=0.0,\n",
        "        nbins=6\n",
        "    )\n",
        "\n",
        "    # Create scatter plot: feature value vs target, colored by SHAP\n",
        "    sc = ax.scatter(\n",
        "        X_train[feature_name],\n",
        "        y_train,\n",
        "        c=shap_col,\n",
        "        cmap=cmap_local,\n",
        "        norm=norm,\n",
        "        alpha=1.0,\n",
        "        s=40,\n",
        "        edgecolor='black',\n",
        "        linewidth=0.25,\n",
        "        marker='o'\n",
        "    )\n",
        "\n",
        "    # Add colorbar with scientific notation\n",
        "    divider = make_axes_locatable(ax)\n",
        "    cax = divider.append_axes('right', size='5%', pad=0.05)\n",
        "    cbar = fig.colorbar(sc, cax=cax)\n",
        "\n",
        "    # Configure colorbar ticks\n",
        "    cbar.set_ticks(ticks)\n",
        "    cbar.formatter = mticker.ScalarFormatter(useMathText=False)\n",
        "    cbar.formatter.set_powerlimits((-2, 3))\n",
        "    cbar.update_ticks()\n",
        "    cbar.ax.tick_params(labelsize=11)\n",
        "    cbar.set_label('SHAP Value', fontsize=12, labelpad=5)\n",
        "\n",
        "    # Configure axes\n",
        "    ax.yaxis.set_major_locator(mticker.MaxNLocator(nbins=5, integer=True))\n",
        "    ax.xaxis.set_major_locator(mticker.MaxNLocator(min_n_ticks=3, nbins=4, integer=True))\n",
        "    ax.set_xlabel(feature_name, fontsize=12, labelpad=4)\n",
        "    ax.set_ylabel(\"Coercivity (A/m)\", fontsize=12, labelpad=4)\n",
        "    ax.tick_params(axis='both', labelsize=11, pad=4)\n",
        "    ax.grid(True, linestyle=':', alpha=0.35, linewidth=0.45)\n",
        "\n",
        "# Save high-resolution figure\n",
        "plt.savefig('WenAlloys_Grid-SHAP_Hc_XGB.png',\n",
        "            dpi=600,\n",
        "            bbox_inches='tight',\n",
        "            facecolor='white')\n",
        "plt.show()\n",
        "\n",
        "# Download in Colab environment\n",
        "try:\n",
        "    files.download('WenAlloys_Grid-SHAP_Hc_XGB.png')\n",
        "except:\n",
        "    pass  # Skip download for local execution"
      ],
      "metadata": {
        "id": "p8SZPyEgYd2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Results**"
      ],
      "metadata": {
        "id": "0L8Hqqh5wFLb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# After evaluating all models, add this to display and save results:\n",
        "def display_model_results(results_df):\n",
        "    \"\"\"Display and save model comparison results\"\"\"\n",
        "    # Format display\n",
        "    pd.options.display.float_format = '{:.4f}'.format\n",
        "    results_df.set_index('Model', inplace=True)\n",
        "\n",
        "    print(\"\\nFinal Model Comparison:\")\n",
        "    print(\"=\"*60)\n",
        "    print(results_df)\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Highlight best scores\n",
        "    def highlight_metrics(s):\n",
        "        metrics = {'MAE': 'min', 'MSE': 'min', 'RMSE': 'min', 'R²': 'max'}\n",
        "        styles = []\n",
        "        for v in s:\n",
        "            if s.name in metrics:\n",
        "                if metrics[s.name] == 'min' and v == s.min():\n",
        "                    styles.append('background-color: yellow')\n",
        "                elif metrics[s.name] == 'max' and v == s.max():\n",
        "                    styles.append('background-color: lightgreen')\n",
        "                else:\n",
        "                    styles.append('')\n",
        "            else:\n",
        "                styles.append('')\n",
        "        return styles\n",
        "\n",
        "    styled_df = results_df.style.apply(highlight_metrics)\n",
        "    display(styled_df)\n",
        "\n",
        "    # Save to Excel\n",
        "    results_df.to_excel('WenAlloys_Hc_metrics.xlsx')\n",
        "    print(\"\\nResults saved to 'WenAlloys_Hc_metrics.xlsx'\")\n",
        "\n",
        "\n",
        "# Call this after evaluating all models\n",
        "display_model_results(model_results)\n",
        "\n",
        "# Download file (Colab only)\n",
        "try:\n",
        "    files.download('WenAlloys_Hc_metrics.xlsx')\n",
        "except:\n",
        "    pass"
      ],
      "metadata": {
        "id": "6_OqZ3uOwLks"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}